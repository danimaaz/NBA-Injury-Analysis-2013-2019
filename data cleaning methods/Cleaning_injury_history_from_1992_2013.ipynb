{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cleaning injury history from 1992-2013.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHI5AJ-s7nuh",
        "outputId": "7c27546c-24ec-42af-e0d5-cb36572d3fff"
      },
      "source": [
        "!pip install --upgrade gupload\n",
        "from pydrive.auth import GoogleAuth\n",
        "from google.colab import auth\n",
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "import datetime\n",
        "from timeit import default_timer as timer\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import drive\n",
        "auth.authenticate_user()\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "df = pd.read_csv('/content/gdrive/My Drive/PST_IL_movement_1992-2020.csv')\n",
        "df['Date']=pd.to_datetime(df['Date'])\n",
        "end_date = df['Date']<'2013-07-01'\n",
        "df = df[end_date]\n",
        "def determine_affected_player(row):\n",
        "  if type(row['Acquired'])==str:\n",
        "    return row['Acquired']\n",
        "  if type(row['Relinquished'])==str:\n",
        "    return row['Relinquished']\n",
        "df['Affected Player']=df.apply(lambda row:determine_affected_player(row), axis=1)\n",
        "start_season = 1992\n",
        "end_year_season = 93\n",
        "seasons_yr_start =[]\n",
        "seasons_yr_end =[]\n",
        "for i in range(21):\n",
        "  seasons_yr_start.append(str(start_season+i))\n",
        "  if not (i>6):\n",
        "    seasons_yr_end.append(str(end_year_season+i))\n",
        "for z in range(14):\n",
        "  if z<10:\n",
        "    seasons_yr_end.append('0'+str(z))\n",
        "  else:\n",
        "    seasons_yr_end.append(str(z))\n",
        "season_names=[]\n",
        "for r in range(len(seasons_yr_start)):\n",
        "  season_names.append(seasons_yr_start[r]+'-' + seasons_yr_end[r])\n",
        "print(season_names)\n",
        "season_dates = {}\n",
        "start_date = '{}-07-01'\n",
        "end_date = '{}-06-30'\n",
        "for szn in season_names:\n",
        "  start_year = int(szn[0:4])\n",
        "  end_year = start_year+1\n",
        "  season_dates[szn]=[start_date.format(start_year),end_date.format(end_year)]\n",
        "print(season_dates)\n",
        "\n",
        "#Creating a function to determine exactly which season each injury took place in\n",
        "\n",
        "def determine_szn(row):\n",
        "  key_list = list(season_dates.keys())\n",
        "  val_list = list(season_dates.values())\n",
        "  for key,value in season_dates.items():\n",
        "    strtdate = datetime.datetime.strptime(value[0], '%Y-%m-%d')\n",
        "    enddate = datetime.datetime.strptime(value[1], '%Y-%m-%d')\n",
        "    if ((row['Date']>=strtdate) and (row['Date']<=enddate)):\n",
        "      pos = val_list.index(value)\n",
        "      szn = key_list[pos]\n",
        "      return szn\n",
        "df['Season']=df.apply(lambda row:determine_szn(row), axis=1)\n",
        "season_dates['2013-14'] = ['2013-07-01']\n",
        "print('part 1 done')\n",
        "\n",
        "#function to clean the 'Notes' column \n",
        "\n",
        "def clean_notes_col_pt_1(row):\n",
        "  s = row['Notes']\n",
        "  if '(' in s.lower():\n",
        "    if s.count('(')==1:\n",
        "      pt1 = s.index('(')\n",
        "      pt2 = s.index(')')\n",
        "      chk1=s[pt1:(pt2+1)]\n",
        "      if 'out' in chk1:\n",
        "        return s\n",
        "      else:\n",
        "        s = s.replace(chk1,'')\n",
        "        return s\n",
        "    if s.count('(')>1:\n",
        "      pt1 = s.index('(')\n",
        "      pt2 = s.index(')')\n",
        "      chk1=s[pt1:(pt2+1)]\n",
        "      chk1s = chk1.lower()\n",
        "      pt3 = s.rindex('(')\n",
        "      pt4 = s.rindex(')')\n",
        "      nextchk1=s[pt3:(pt4+1)]\n",
        "      nextchk1s=nextchk1.lower()\n",
        "      nextchk1\n",
        "      if ('out' in chk1s) and (not ('out' in nextchk1s)):\n",
        "        s=s.replace(nextchk1,'')\n",
        "        return s\n",
        "      if (not ('out' in chk1s)) and ('out' in nextchk1s):\n",
        "        s=s.replace(chk1,'')\n",
        "        return s\n",
        "      if (not ('out' in chk1s)) and (not ('out' in nextchk1s)):\n",
        "        s = s.replace(nextchk1,'')\n",
        "        s = s.replace(chk1,'')\n",
        "        return s\n",
        "      if ('out' in chk1s) and ('out' in nextchk1s):\n",
        "        print(4)\n",
        "        s = s.replace(nextchk1,'')\n",
        "        return s\n",
        "  else:\n",
        "    return s\n",
        "df['Notes']=df.apply(lambda row:clean_notes_col_pt_1(row), axis=1)\n",
        "\n",
        "copied_df = df.copy()\n",
        "!pip install nba_api\n",
        "#cleaning the names of the nba players\n",
        "from nba_api.stats.static import players\n",
        "from nba_api.stats.static import teams \n",
        "from nba_api.stats.endpoints import boxscoreplayertrackv2\n",
        "from nba_api.stats.endpoints import leaguegamelog\n",
        "from nba_api.stats.endpoints import leaguegamefinder\n",
        "import pandas as pd\n",
        "from nba_api.stats.static import teams\n",
        "from nba_api.stats.endpoints import leaguegamefinder\n",
        "from datetime import datetime,timedelta\n",
        "import time\n",
        "\n",
        "acqcl = copied_df.columns.get_loc('Acquired')\n",
        "rcl = copied_df.columns.get_loc('Relinquished')\n",
        "acl = copied_df.columns.get_loc('Affected Player')\n",
        "player_dict = players.get_players()\n",
        "lst_of_player_names = []\n",
        "names_not_in_nba_api = []\n",
        "for key in player_dict:\n",
        "  lst_of_player_names.append((key['full_name']))\n",
        "rng = copied_df.shape[0]\n",
        "\n",
        "#function to change the names of each player such that \n",
        "#their name on the data corresponds to the name that they \n",
        "#are listed under on the nba.com website\n",
        "for i in range(rng):\n",
        "  row = copied_df.iloc[i,:]\n",
        "  player_name = row.loc['Affected Player']\n",
        "  relinquished_name = row.loc['Relinquished']\n",
        "  acquired_name = row.loc['Acquired']\n",
        "  if player_name == acquired_name:\n",
        "    for nba_name in lst_of_player_names:\n",
        "      if nba_name in player_name:\n",
        "        copied_df.iat[i,acqcl] = nba_name\n",
        "        copied_df.iat[i,acl] = nba_name\n",
        "  else:\n",
        "    for nba_name in lst_of_player_names:\n",
        "      if nba_name in player_name:\n",
        "        copied_df.iat[i,rcl] = nba_name\n",
        "        copied_df.iat[i,acl] = nba_name\n",
        "\n",
        "\n",
        "print('part 3 done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gupload\n",
            "  Downloading https://files.pythonhosted.org/packages/b5/ea/cd751e2eb1c8957bb6e5fb9c2e0329be5904fc9b432617bb2e83681834dd/gupload-1.1.0-py3-none-any.whl\n",
            "Collecting google-api-python-client==1.7.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/4b/66b7591b83864caef0d960aefd05a110bcf9cb18cc6dd957414e34861530/google_api_python_client-1.7.10-py3-none-any.whl (56kB)\n",
            "\r\u001b[K     |█████▉                          | 10kB 20.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 20kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 30kB 28.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 40kB 31.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 51kB 33.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 8.2MB/s \n",
            "\u001b[?25hCollecting click==7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/37/45185cb5abbc30d7257104c434fe0b07e5a195a6847506c074527aa599ec/Click-7.0-py2.py3-none-any.whl (81kB)\n",
            "\r\u001b[K     |████                            | 10kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 20kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 30kB 28.3MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 40kB 31.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 51kB 34.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 61kB 36.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 71kB 37.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 10.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.7.10->gupload) (0.17.4)\n",
            "Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.7.10->gupload) (3.0.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.7.10->gupload) (1.31.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.7.10->gupload) (0.0.4)\n",
            "Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.7.10->gupload) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.7.10->gupload) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.7.10->gupload) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.7.10->gupload) (4.2.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.7.10->gupload) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client==1.7.10->gupload) (0.4.8)\n",
            "\u001b[31mERROR: earthengine-api 0.1.269 has requirement google-api-python-client<2,>=1.12.1, but you'll have google-api-python-client 1.7.10 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-api-python-client, click, gupload\n",
            "  Found existing installation: google-api-python-client 1.12.8\n",
            "    Uninstalling google-api-python-client-1.12.8:\n",
            "      Successfully uninstalled google-api-python-client-1.12.8\n",
            "  Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "Successfully installed click-7.0 google-api-python-client-1.7.10 gupload-1.1.0\n",
            "Mounted at /content/gdrive\n",
            "['1992-93', '1993-94', '1994-95', '1995-96', '1996-97', '1997-98', '1998-99', '1999-00', '2000-01', '2001-02', '2002-03', '2003-04', '2004-05', '2005-06', '2006-07', '2007-08', '2008-09', '2009-10', '2010-11', '2011-12', '2012-13']\n",
            "{'1992-93': ['1992-07-01', '1993-06-30'], '1993-94': ['1993-07-01', '1994-06-30'], '1994-95': ['1994-07-01', '1995-06-30'], '1995-96': ['1995-07-01', '1996-06-30'], '1996-97': ['1996-07-01', '1997-06-30'], '1997-98': ['1997-07-01', '1998-06-30'], '1998-99': ['1998-07-01', '1999-06-30'], '1999-00': ['1999-07-01', '2000-06-30'], '2000-01': ['2000-07-01', '2001-06-30'], '2001-02': ['2001-07-01', '2002-06-30'], '2002-03': ['2002-07-01', '2003-06-30'], '2003-04': ['2003-07-01', '2004-06-30'], '2004-05': ['2004-07-01', '2005-06-30'], '2005-06': ['2005-07-01', '2006-06-30'], '2006-07': ['2006-07-01', '2007-06-30'], '2007-08': ['2007-07-01', '2008-06-30'], '2008-09': ['2008-07-01', '2009-06-30'], '2009-10': ['2009-07-01', '2010-06-30'], '2010-11': ['2010-07-01', '2011-06-30'], '2011-12': ['2011-07-01', '2012-06-30'], '2012-13': ['2012-07-01', '2013-06-30']}\n",
            "part 1 done\n",
            "part 2 done\n",
            "Collecting nba_api\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/07/d32f5106c95fbee8e54b22d2795f94c2d2213ed6d2e5caac390b56667d37/nba_api-1.1.9-py3-none-any.whl (242kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 25.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from nba_api) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->nba_api) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->nba_api) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->nba_api) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->nba_api) (1.24.3)\n",
            "Installing collected packages: nba-api\n",
            "Successfully installed nba-api-1.1.9\n",
            "part 3 done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cpsTsxI7q2a",
        "outputId": "cf5286ee-828d-4a01-ef2e-db0539472a7e"
      },
      "source": [
        "rng = df.shape[0]\n",
        "#function to determine exactly\n",
        "#what type of injury each player has incurred\n",
        "\n",
        "def type_of_injury(row):\n",
        "  notes = row['Notes']\n",
        "  Injured_player = row['Relinquished']\n",
        "  if type(Injured_player)==str:\n",
        "    if (('IR' in notes) and ('with' in notes)):\n",
        "      y = notes[:18]\n",
        "      notes.replace(y,'')\n",
        "      if '(' in notes:\n",
        "        pos1 = notes.index('(')\n",
        "        r = notes[pos1:]\n",
        "        notes = notes.replace(r,'')\n",
        "        if '&' in notes:\n",
        "          pos2 = notes.index('&')\n",
        "          u = notes[pos2] \n",
        "          notes = notes.replace(u,'')\n",
        "          return notes\n",
        "        elif '/' in notes:\n",
        "          pos3=notes.index('/')\n",
        "          z = notes[pos3:]\n",
        "          notes = notes.replace(z,'')\n",
        "          return notes\n",
        "        else:\n",
        "          return notes\n",
        "      elif '&' in notes:\n",
        "        pos2 = notes.index('&')\n",
        "        u = notes[pos2] \n",
        "        notes = notes.replace(u,'')\n",
        "        return notes\n",
        "      elif '/' in notes:\n",
        "        pos3=notes.index('/')\n",
        "        z = notes[pos3:]\n",
        "        notes = notes.replace(z,'')\n",
        "        return notes\n",
        "      else:\n",
        "        return notes\n",
        "    elif (('IL' in notes) and ('with' in notes)):\n",
        "      y = notes[:18]\n",
        "      notes = notes.replace(y,'')\n",
        "      if '(' in notes:\n",
        "        pos1 = notes.index('(')\n",
        "        r = notes[pos1:]\n",
        "        notes = notes.replace(r,'')\n",
        "        if '&' in notes:\n",
        "          pos2 = notes.index('&')\n",
        "          u = notes[pos2:] \n",
        "          notes = notes.replace(u,'')\n",
        "          return notes\n",
        "        elif '/' in notes:\n",
        "          pos3=notes.index('/')\n",
        "          z = notes[pos3:]\n",
        "          notes = notes.replace(z,'')\n",
        "          return notes\n",
        "        else:\n",
        "          return notes\n",
        "      elif '&' in notes:\n",
        "        pos2 = notes.index('&')\n",
        "        u = notes[pos2:] \n",
        "        notes = notes.replace(u,'')\n",
        "        return notes\n",
        "      elif '/' in notes:\n",
        "        pos3=notes.index('/')\n",
        "        z = notes[pos3:]\n",
        "        notes = notes.replace(z,'')\n",
        "        return notes\n",
        "      else:\n",
        "        return notes\n",
        "    else:\n",
        "      rep = notes[:11]\n",
        "      notes = notes.replace(rep,'')\n",
        "      return notes\n",
        "df['Injury Type']=df.apply(lambda row:type_of_injury(row), axis=1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "part 4 done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbeHZ5iB8GG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "099c1586-f241-4dce-fd48-d15959275a1b"
      },
      "source": [
        "rng = df.shape[0]\n",
        "dict_of_incomplete_players = {}\n",
        "indicies_to_drop = []\n",
        "season_names.append('2013-14')\n",
        "\n",
        "#deleting consecutive instances of relinquished players (when player is not out for the season)\n",
        "#and next relinquished occurs \n",
        "for i in range(rng):\n",
        "  row = df.iloc[i,:]\n",
        "  player_name = row.loc['Affected Player']\n",
        "  relinquished_name = row.loc['Relinquished']\n",
        "  notes_first = row.loc['Notes']\n",
        "  season_first = row.loc['Season']\n",
        "  impindex = season_names.index(season_first)\n",
        "  season_next = season_names[impindex+1] \n",
        "  if type(relinquished_name)==str:\n",
        "    for r in range(i+1,rng):\n",
        "      list_to_append = [i,r]\n",
        "      next_row = df.iloc[r,:]\n",
        "      notes_second = row.loc['Notes']\n",
        "      acquired_name = next_row.loc['Acquired']\n",
        "      season_second = next_row.loc['Season']\n",
        "      next_relinquished_name = next_row.loc['Relinquished']\n",
        "      next_player_name=next_row.loc['Affected Player']\n",
        "      if (next_player_name == player_name):\n",
        "        if (acquired_name==player_name):\n",
        "          break\n",
        "        else:\n",
        "          if (('out for season' in notes_first) or ('out for season' in notes_second)):\n",
        "            if season_second == season_next:\n",
        "              if player_name in dict_of_incomplete_players:\n",
        "                dict_of_incomplete_players[player_name].append(list_to_append)\n",
        "                break\n",
        "              else:\n",
        "                dict_of_incomplete_players[player_name]=[list_to_append]\n",
        "                break\n",
        "            else:\n",
        "              break              \n",
        "          else:\n",
        "            indicies_to_drop.append(i)\n",
        "            break\n",
        "print(indicies_to_drop)\n",
        "# print(dict_of_incomplete_players)\n",
        "JUST_IN_CASE = df.copy()\n",
        "\n",
        "df = df.reset_index(drop=True)\n",
        "df = df.drop(labels=indicies_to_drop,axis=0)\n",
        "df = df.reset_index(drop=True)\n",
        "copied_df = df.copy()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8, 12, 17, 18, 36, 41, 50, 56, 74, 78, 94, 95, 100, 107, 108, 111, 161, 191, 229, 292, 321, 332, 459, 486, 510, 562, 663, 664, 667, 688, 697, 759, 909, 999, 1060, 1113, 1219, 1224, 1252, 1290, 1318, 1347, 1379, 1413, 1437, 1485, 1492, 1506, 1531, 1710, 1738, 1740, 1748, 1767, 1781, 1789, 1801, 1889, 1910, 1940, 1950, 1952, 2053, 2102, 2147, 2223, 2224, 2228, 2235, 2262, 2433, 2444, 2445, 2512, 2533, 2547, 2556, 2615, 2632, 2633, 2634, 2635, 2636, 2637, 2638, 2639, 2640, 2641, 2642, 2643, 2657, 2659, 2685, 2735, 2737, 2746, 2777, 2794, 2833, 2864, 2913, 2922, 2966, 3038, 3041, 3042, 3052, 3057, 3086, 3109, 3112, 3116, 3120, 3125, 3127, 3129, 3139, 3146, 3151, 3156, 3159, 3161, 3171, 3181, 3182, 3195, 3196, 3199, 3201, 3241, 3260, 3270, 3312, 3325, 3387, 3421, 3431, 3536, 3538, 3586, 3600, 3619, 3645, 3654, 3691, 3722, 3733, 3896, 3928, 3942, 3961, 3967, 3972, 4096, 4114, 4149, 4182, 4231, 4256, 4280, 4284, 4327, 4335, 4337, 4363, 4399, 4401, 4403, 4411, 4413, 4433, 4449, 4456, 4462, 4472, 4474, 4480, 4491, 4495, 4497, 4538, 4556, 4561, 4562, 4565, 4584, 4586, 4596, 4626, 4672, 4764, 4775, 4781, 4811, 4838, 4843, 4850, 4867, 4868, 4877, 4882, 4892, 4894, 4911, 4914, 4918, 4955, 4973, 4980, 4981, 4984, 4992, 4998, 5004, 5006, 5010, 5012, 5014, 5015, 5016, 5020, 5021, 5039, 5046, 5047, 5060, 5062, 5068, 5077, 5084, 5099, 5117, 5135, 5141, 5162, 5178, 5180, 5211, 5228, 5238, 5250, 5256, 5259, 5261, 5290, 5293, 5295, 5299, 5302, 5304, 5331, 5367, 5378, 5391, 5405, 5425, 5433, 5446, 5448, 5463, 5492, 5517, 5520, 5527, 5530, 5531, 5535, 5536, 5551, 5553, 5557, 5559, 5563, 5565, 5567, 5568, 5569, 5571, 5572, 5573, 5605, 5606, 5613, 5622, 5634, 5659, 5706, 5780, 5896, 5939, 5962, 5966, 5990, 5993, 5997, 5999, 6060, 6079, 6109, 6119, 6133, 6140, 6167, 6170, 6185, 6186, 6190, 6193, 6209, 6210, 6228, 6234, 6236, 6247, 6255, 6263, 6265, 6267, 6269, 6276, 6279, 6285, 6287, 6293, 6296, 6298, 6302, 6303, 6305, 6307, 6309, 6311, 6313, 6323, 6325, 6329, 6331, 6334, 6336, 6338, 6339, 6342, 6344, 6346, 6348, 6350, 6367, 6391, 6398, 6405, 6415, 6426, 6475, 6480, 6484, 6497, 6578, 6585, 6592, 6605, 6613, 6615, 6645, 6651, 6655, 6670, 6730, 6782, 6805, 6860, 6869, 6874, 6987, 7049, 7067, 7084, 7095, 7120, 7131, 7162, 7171, 7175, 7181, 7185, 7193, 7215, 7221, 7225, 7227, 7228, 7249, 7262, 7267, 7274, 7276, 7293, 7297, 7301, 7320, 7329, 7330, 7383, 7387, 7394, 7413, 7444, 7460, 7462, 7496, 7498, 7525, 7591, 7598, 7667, 7671, 7683, 7720, 7722, 7726, 7744, 7748, 7760, 7777, 7779, 7795, 7808, 7823, 7834, 7836, 7849, 7877, 7894, 7900, 7916, 7918, 7923, 7934, 7937, 7939, 7943, 7953, 7955, 7959, 7963, 7965, 7967, 7975, 7979, 7981, 7982, 7985, 7986, 7987, 7989, 7990, 7993, 7995, 7996, 7998, 8000, 8001, 8002, 8006, 8007, 8014, 8016, 8017, 8019, 8024, 8025, 8030, 8032, 8034, 8040, 8049, 8053, 8058, 8064, 8069, 8075, 8096, 8097, 8106, 8109, 8163, 8203, 8221, 8230, 8236, 8275, 8284, 8289, 8299, 8308, 8346, 8382, 8399, 8429, 8464, 8482, 8533, 8770, 8776, 8790, 8875, 8895, 8945, 8996, 9016, 9059, 9065, 9163, 9188, 9253, 9285, 9296, 9303, 9308, 9359, 9376, 9388, 9404, 9435, 9452, 9457, 9469, 9494, 9531, 9543, 9546, 9561, 9593, 9619, 9629, 9649, 9650, 9664, 9683, 9692, 9705, 9712, 9754, 9756, 9761, 9765, 9773, 9776, 9787, 9812, 9820, 9832, 9838, 9843, 9868, 9894, 9895, 9898, 9899, 9900, 9904, 9905, 9911, 9912, 9917, 9921, 9923, 9925, 9926, 9927, 9931, 9934, 9937, 9938, 9941, 9943, 9945, 9946, 9951, 9952, 9955, 9958, 9959, 9960, 9962, 9966, 9972, 9980, 9982, 9984, 9989, 9990, 9992, 9993, 9995, 9997, 9998, 9999, 10005, 10007, 10015, 10033, 10039, 10042, 10065, 10113, 10278, 10318, 10346, 10403, 10407, 10424, 10513, 10575, 10584, 10640, 10673, 10679, 10750, 10752, 10767, 10840, 10860, 10871, 10875, 10880, 10904, 10905, 10955, 10986, 11020, 11027, 11031, 11060, 11071, 11096, 11131, 11202, 11214, 11221, 11222, 11233, 11327, 11360, 11364, 11374, 11376, 11391, 11410, 11416, 11418, 11426, 11428, 11437, 11443, 11460, 11472, 11474, 11476, 11478, 11479, 11481, 11482, 11485, 11489, 11490, 11493, 11494, 11499, 11505, 11507, 11510, 11532, 11538, 11540, 11542, 11546, 11548, 11550, 11556, 11558, 11564, 11578, 11597, 11615, 11621, 11625, 11631, 11634, 11640, 11685, 11708, 12036, 12094, 12126, 12139, 12185, 12262, 12327, 12346, 12350, 12408, 12457, 12472, 12484, 12516, 12569, 12588, 12608, 12613, 12636, 12649, 12682, 12723, 12748, 12776, 12799, 12803, 12810, 12818, 12827, 12843, 12883, 12913, 12918, 12950, 13002, 13018, 13021, 13025, 13035, 13037, 13042, 13045, 13058, 13061, 13063, 13070, 13071, 13076, 13088, 13124, 13145, 13182, 13185, 13275, 13390, 13410, 13428, 13446, 13487, 13514, 13549, 13559, 13583, 13601, 13627, 13656, 13660, 13681, 13707, 13713, 13721, 13737, 13769, 13775, 13776, 13834, 13857, 13908, 13926, 13974, 14021, 14023, 14025, 14044, 14065, 14074, 14119, 14140, 14148, 14152, 14183, 14187, 14319, 14358, 14373, 14387, 14404, 14413, 14434, 14464, 14511, 14514, 14515, 14526, 14528, 14540, 14541, 14543, 14549, 14557, 14570, 14595, 14624, 14625, 14656, 14761, 14775, 14792, 14903, 14916, 15064, 15075, 15077, 15079, 15118, 15155, 15157, 15210, 15341, 15419, 15491, 15596, 15608, 15653, 15686, 15709, 15767, 15778, 15786, 15789, 15814, 15827, 15881, 16065, 16066, 16151, 16173, 16262, 16269, 16280, 16286, 16293, 16302, 16306, 16312, 16313, 16315, 16320, 16321, 16329, 16353, 16403, 16445, 16462, 16484, 16529, 16608, 16626, 16642, 16676, 16690, 16697, 16712, 16718, 16727, 16778, 16779, 16782, 16793, 16794, 16808, 16811, 16824, 16834, 16837, 16841, 16859, 16870, 16873, 16877, 16885, 16899, 16912, 16914, 16925, 16952, 16953, 16966, 16972, 16977, 16982, 17013, 17018, 17019, 17058, 17094, 17095, 17119, 17139, 17143, 17144, 17177, 17181, 17352, 17361, 17367, 17371, 17376, 17381, 17499, 17662, 17923, 17929, 17960, 18054, 18059, 18114, 18327, 18518, 18534, 18536]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2ao_-jh8GdJ",
        "outputId": "7312e5a7-d6be-4136-f638-ea8a6ecc29d0"
      },
      "source": [
        "#finding instances where next occurence\n",
        "#of being acquired (after initially being acquired)\n",
        "#occurs in the same season and deleting the latter occurence\n",
        "\n",
        "rng = df.shape[0]\n",
        "double_acquired = []\n",
        "for i in range(rng):\n",
        "  row = copied_df.iloc[i,:]\n",
        "  notes = row.loc['Notes']\n",
        "  player_name = row.loc['Affected Player']\n",
        "  relinquished_name = row.loc['Relinquished']\n",
        "  acquired_name = row.loc['Acquired']\n",
        "  season_first = row.loc['Season']\n",
        "  if player_name == acquired_name:\n",
        "    for z in range(i+1,rng):\n",
        "      next_row = copied_df.iloc[z,:]\n",
        "      next_player_name = next_row.loc['Affected Player']\n",
        "      next_relinquished_name = next_row.loc['Relinquished']\n",
        "      next_acquired_name = next_row.loc['Acquired']\n",
        "      next_season = next_row.loc['Season']\n",
        "      next_notes = next_row.loc['Notes']\n",
        "      if season_first == next_season:\n",
        "        if player_name == next_player_name:\n",
        "          if player_name == next_acquired_name and (season_first==next_season):\n",
        "            double_acquired.append(i)\n",
        "            break\n",
        "          else:\n",
        "            break\n",
        "      else:\n",
        "        break\n",
        "\n",
        "\n",
        "print('part 5 done')          \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "part 5 done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFpO9ezH8NmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab7b0d8b-4043-4ee0-d2ee-1c653158f739"
      },
      "source": [
        "new_dropping_list = sorted(double_acquired)\n",
        "df=df.reset_index(drop=True)\n",
        "df = df.drop(labels=new_dropping_list,axis=0) \n",
        "df=df.reset_index(drop=True)\n",
        "copied_df = df.copy()\n",
        "\n",
        "\n",
        "\n",
        "#finding instances where next occurence\n",
        "#of being relinquished (after initially being relinquished)\n",
        "#occurs in the same season\n",
        "rng = copied_df.shape[0]\n",
        "ghost_injury = []\n",
        "names = {}\n",
        "more_shit_to_drop_doubleacquired = []\n",
        "for i in range(rng):\n",
        "  row = copied_df.iloc[i,:]\n",
        "  notes = row.loc['Notes']\n",
        "  player_name = row.loc['Affected Player']\n",
        "  relinquished_name = row.loc['Relinquished']\n",
        "  season_first = row.loc['Season']\n",
        "  if player_name == relinquished_name:\n",
        "    for z in range(i+1,rng):\n",
        "      next_row = copied_df.iloc[z,:]\n",
        "      next_player_name = next_row.loc['Affected Player']\n",
        "      next_relinquished_name = next_row.loc['Relinquished']\n",
        "      next_acquired_name = next_row.loc['Acquired']\n",
        "      next_season = next_row.loc['Season']\n",
        "      next_notes = next_row.loc['Notes']\n",
        "      if player_name == next_player_name:\n",
        "        if player_name == next_acquired_name:\n",
        "          break\n",
        "        elif player_name == next_relinquished_name:\n",
        "          if season_first == next_season:\n",
        "            ghost_injury.append(i)\n",
        "            if player_name in names:\n",
        "              names[player_name].append([i,z])\n",
        "              break\n",
        "            else:\n",
        "              names[player_name] = [[i,z]]\n",
        "              break\n",
        "            break\n",
        "df = df.reset_index(drop=True)\n",
        "copied_df = df.copy()\n",
        "\n",
        "\n",
        "print('part 6 done')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "part 6 done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTYU0WMs8WRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84e85813-e381-441d-ac33-7e21c78577f9"
      },
      "source": [
        "\n",
        "#newdict_out are players who were out for the \n",
        "#season and got another injury/update\n",
        "#consider removing instances where they're given surgery\n",
        "newdict_out = {}\n",
        "#newdict_notout4szn are players who weren't considered out for either portion of the year\n",
        "newdict_notout4szn = {}\n",
        "consider_dropping = []\n",
        "#others are players who were out for surgery at first\n",
        "#but came back? go through separately\n",
        "\n",
        "others = {}\n",
        "#sorting through these double occurences of relinquished\n",
        "#if they are relisted for being out for surgery\n",
        "#remove the instance of surgery\n",
        "#if they are listed out for the season for surgery FIRST\n",
        "#and relisted on the list for some reason\n",
        "#evaluate instances separetely \n",
        "\n",
        "\n",
        "for key,value in names.items():\n",
        "  if len(value)==1:\n",
        "    indx_one = value[0][0]\n",
        "    indx_two = value[0][1]\n",
        "    row_one = copied_df.iloc[indx_one,:]\n",
        "    row_two = copied_df.iloc[indx_two,:]\n",
        "    notes_one = row_one.loc['Notes']\n",
        "    notes_two = row_two.loc['Notes']\n",
        "    if ('out' in notes_one) or ('out' in notes_two):\n",
        "      if 'surgery' in notes_two:\n",
        "        consider_dropping.append(indx_two)\n",
        "      elif 'surgery' in notes_one:\n",
        "        others[key]=value\n",
        "      elif key in newdict_out:\n",
        "        newdict_out[key].append(value)\n",
        "      else:\n",
        "        newdict_out[key]=value\n",
        "    else:\n",
        "      if key in newdict_notout4szn:\n",
        "        newdict_notout4szn[key].append(value)\n",
        "      else:\n",
        "        newdict_notout4szn[key]=value\n",
        "  else:\n",
        "    for val in value:\n",
        "      indx_one = val[0]\n",
        "      indx_two = val[1]\n",
        "      row_one = copied_df.iloc[indx_one,:]\n",
        "      row_two = copied_df.iloc[indx_two,:]\n",
        "      notes_one = row_one.loc['Notes']\n",
        "      notes_two = row_two.loc['Notes']\n",
        "      if ('out' in notes_one) or ('out' in notes_two):\n",
        "        if 'surgery' in notes_two:\n",
        "          consider_dropping.append(indx_two)\n",
        "        elif 'surgery' in notes_one:\n",
        "          others[key]=val\n",
        "        elif key in newdict_out:\n",
        "          newdict_out[key].append(val)\n",
        "        else:\n",
        "          newdict_out[key]=val\n",
        "      else:\n",
        "        if key in newdict_notout4szn:\n",
        "          newdict_notout4szn[key].append(val)\n",
        "        else:\n",
        "          newdict_notout4szn[key]=val\n",
        "\n",
        "print(newdict_out)\n",
        "print('above is newdict_out')\n",
        "print(newdict_notout4szn)\n",
        "print('above is newdict_notout4szn')\n",
        "print(consider_dropping)\n",
        "print('rows to consider dropping is above')\n",
        "print(others)\n",
        "print('above is the others dict')\n",
        "df = df.drop(labels=ghost_injury,axis=0)\n",
        "df=df.reset_index(drop=True)\n",
        "copied_df = df.copy()\n",
        "backup = df.copy()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Elliot Williams': [[16022, 16056]], 'Andray Blatche': [[16077, 16104]], 'Emeka Okafor': [[16117, 16139]]}\n",
            "above is newdict_out\n",
            "{}\n",
            "above is newdict_notout4szn\n",
            "[]\n",
            "rows to consider dropping is above\n",
            "{'Mitchell Butler': [[1237, 1387]], 'Jermareo Davidson': [[12072, 12141]]}\n",
            "above is the others dict\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ynBN9Wq8aKk"
      },
      "source": [
        "df = backup.copy()\n",
        "#an injury categorizing function that \n",
        "#determines exactly WHICH body part got injured\n",
        "\n",
        "def injury_categorizer(row):\n",
        "  injury_type = row['Notes']\n",
        "  relinquished_player = row['Relinquished']\n",
        "  player_name = row.loc['Affected Player']\n",
        "  if relinquished_player == player_name:\n",
        "    injury_type = injury_type.lower()\n",
        "    foot = ['toe','heel','metatarsal','ankle','achilles','achilled','foot','feet','plantar','metatasalgia']\n",
        "    upper_leg = ['thigh','abductor','buttock','adductor','hamstring','groin','femur','leg','quadricep']\n",
        "    knee=['acl','mcl','knee','meniscus','patella']\n",
        "    lower_leg = ['tibia','shin','fibula','calf']\n",
        "    arm = ['bicep','tricep','arm','elbow']\n",
        "    hand = ['wrist','pinky','finger','thumb','hand']\n",
        "    upper_body = ['clavicle','sternum','pectoral','chest','shoulder','rotator','delt']\n",
        "    core_and_hip = ['abdom','adominal','oblique','rib','stomach muscle','hip']\n",
        "    head_and_neck = ['facial','cervical','teeth','concussion','face','orbit','tooth','jaw','nose','collarbone','eye','head','neck','cheekbone','dental']\n",
        "    back = ['spine','herniated discs','herniated disc','back','vertebra','herniated','lumbro-sacral','lumbrosacral','lumbar','spinal','tail']\n",
        "\n",
        "    mental_illness = ['depression','mental','clinical']\n",
        "    illness = ['illness','virus','flu','sick','esophagitis','migraine','allergic','allergy','salmonella','nausea','pox','infection','syndrome','viral','stomach','sick','pneumonia','dizziness','poisoning','bronchitis','gastro','strep','adverse reaction','sinus']\n",
        "    miscellaneous = ['personal','family','death','birth','tonsillitis']\n",
        "    if any(i in injury_type for i in foot):\n",
        "      return 'foot'\n",
        "    elif any(i in injury_type for i in lower_leg):\n",
        "      return 'lower leg'\n",
        "    elif any(i in injury_type for i in knee):\n",
        "      return 'knee'\n",
        "    elif any(i in injury_type for i in upper_leg):\n",
        "      return 'upper leg'\n",
        "    elif any(i in injury_type for i in arm):\n",
        "      return 'arm'\n",
        "    elif any(i in injury_type for i in hand):\n",
        "      return 'hand'\n",
        "    elif any(i in injury_type for i in upper_body):\n",
        "      return 'upper body'\n",
        "    elif any(i in injury_type for i in core_and_hip):\n",
        "      return 'core and hip'\n",
        "    elif any(i in injury_type for i in head_and_neck):\n",
        "      return 'head and neck'\n",
        "    elif any(i in injury_type for i in mental_illness):\n",
        "      return 'mental illness'\n",
        "    elif any(i in injury_type for i in back):\n",
        "      return 'back'\n",
        "    elif any(i in injury_type for i in illness):\n",
        "      return 'illness'\n",
        "    elif any(i in injury_type for i in miscellaneous):\n",
        "      return 'miscellaneous'\n",
        "    else:\n",
        "      return 'other'\n",
        "  else:\n",
        "    return 'Acquired'\n",
        "df['Injury Part']=df.apply(lambda x:injury_categorizer(x), axis=1)\n",
        "copied_df=df.copy()\n",
        "backup = df.copy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6elG2OiN8cau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "711ebac4-dc67-4d03-b586-0eaa350017d9"
      },
      "source": [
        "checkpoint_dates = {}\n",
        "beginning_dates_lst = ['1992-11-09', '1993-11-08', '1994-11-07', '1995-11-06', '1996-11-04', '1997-11-03', '1999-02-07', '1999-11-05', '2000-11-03', '2001-11-02', '2002-11-02', '2003-11-01', '2004-11-05', '2005-11-04', '2006-11-03', '2007-11-03', '2008-11-01', '2009-11-01', '2010-11-01', '2011-12-28', '2012-11-03','2013-10-01']\n",
        "for i in range(len(season_names)):\n",
        "  checkpoint_dates[season_names[i]]=beginning_dates_lst[i]\n",
        "seasons_yr_start.append(2013)\n",
        "pseudoreturn = []\n",
        "pseudoreturn_dates = {}\n",
        "b='{}-10-01'\n",
        "for year in seasons_yr_start:\n",
        "  pseudoreturn.append(b.format(year))\n",
        "for i in range(len(beginning_dates_lst)):\n",
        "  pseudoreturn_dates[season_names[i]] = pseudoreturn[i]\n",
        "print(pseudoreturn_dates)\n",
        "print(checkpoint_dates)\n",
        "JUST_IN_CASE_FOUR = df.copy()\n",
        "\n",
        "#finding players who were never 'returned' to the starting lineup after their out for season injuries\n",
        "#adding in a generic row to establish a return date to get approximate injury length\n",
        "#While this is a strong assumption\n",
        "#it is a viable solution considering we do not have the exact data of when a player has 'fully healed'\n",
        "#from a particular injury\n",
        "\n",
        "#also, for players that were out for season and relisted \n",
        "#at the beginning of the next season as out (for an injury to the same body part)\n",
        "#(for presumambly the same injury)\n",
        "#delete the 'inital' row that they were taking up\n",
        "\n",
        "copied_df = df.copy()\n",
        "to_drop = []\n",
        "\n",
        "rng = copied_df.shape[0]\n",
        "for i in range(rng):\n",
        "  row = copied_df.iloc[i,:]\n",
        "  notes = row.loc['Notes']\n",
        "  player_name = row.loc['Affected Player']\n",
        "  relinquished_name = row.loc['Relinquished']\n",
        "  acquired_name = row.loc['Acquired']\n",
        "  season_first = row.loc['Season']\n",
        "  season_first_int = int(season_first[:4])\n",
        "  impindex = season_names.index(season_first)\n",
        "  season_next = season_names[impindex+1]\n",
        "  acquired_note = 'activated from IL'\n",
        "  inj_part = row.loc['Injury Part']\n",
        "  if ((player_name == relinquished_name) and ('out for season' in notes)):\n",
        "    if season_first == '2012-13':\n",
        "      season_next = '2013-14'\n",
        "      date = pseudoreturn_dates[season_next]\n",
        "      Team = row.loc['Team']\n",
        "      row2add = {'Date':date,'Team':Team,'Acquired':player_name,'Relinquished':acquired_name,'Notes':acquired_note,'Affected Player':player_name,'Season':season_next,'Injury Type':'','Injury Part':'Acquired'}\n",
        "      copied_df=copied_df.append(row2add,ignore_index=True)\n",
        "    else:\n",
        "      for z in range(i+1,rng):\n",
        "        next_row = copied_df.iloc[z,:]\n",
        "        next_player_name = next_row.loc['Affected Player']\n",
        "        next_relinquished_name = next_row.loc['Relinquished']\n",
        "        next_acquired_name = next_row.loc['Acquired']\n",
        "        season_second = next_row.loc['Season']\n",
        "        next_notes = next_row.loc['Notes']\n",
        "        second_date = next_row.loc['Date']\n",
        "        Team = next_row.loc['Team']\n",
        "        next_injury_part = next_row.loc['Injury Part']\n",
        "        season_second_int = int(season_second[:4])\n",
        "        if player_name == next_player_name:\n",
        "          if player_name == next_acquired_name:\n",
        "            if (season_second_int-season_first_int)<3:\n",
        "              break\n",
        "            else:\n",
        "              date_fill = pseudoreturn_dates[season_next]\n",
        "              row2add = {'Date':date_fill,'Team':Team,'Acquired':player_name,'Relinquished':acquired_name,'Notes':acquired_note,'Affected Player':player_name,'Season':season_next,'Injury Type':'','Injury Part':'Acquired'}\n",
        "              df=df.append(row2add,ignore_index=True)\n",
        "              break\n",
        "          else:\n",
        "            if season_second == season_next:\n",
        "              comp_date = datetime.strptime(checkpoint_dates[season_second], '%Y-%m-%d')\n",
        "              if (second_date < comp_date):\n",
        "                if inj_part == next_injury_part:\n",
        "                  if ('out for season' in next_notes):\n",
        "                    season_next = season_names[impindex+2]\n",
        "                    date = pseudoreturn_dates[season_next]\n",
        "                    row2add = {'Date':date,'Team':Team,'Acquired':player_name,'Relinquished':acquired_name,'Notes':acquired_note,'Affected Player':player_name,'Season':season_next,'Injury Type':'','Injury Part':'Acquired'}\n",
        "                    copied_df=copied_df.append(row2add,ignore_index=True)\n",
        "                    to_drop.append(z)\n",
        "                  else:\n",
        "                    to_drop.append(z)\n",
        "                  break\n",
        "                else:\n",
        "                  season_next = season_names[(impindex+1)]\n",
        "                  date = season_dates[season_next][0]\n",
        "                  row2add = {'Date':date,'Team':Team,'Acquired':player_name,'Relinquished':acquired_name,'Notes':acquired_note,'Affected Player':player_name,'Season':season_second,'Injury Type':'','Injury Part':'Acquired'}\n",
        "                  df=df.append(row2add,ignore_index=True)\n",
        "                  break\n",
        "              else:\n",
        "                date = pseudoreturn_dates[season_second]\n",
        "                row2add = {'Date':date,'Team':Team,'Acquired':player_name,'Relinquished':acquired_name,'Notes':acquired_note,'Affected Player':player_name,'Season':season_second,'Injury Type':'','Injury Part':'Acquired'}\n",
        "                copied_df=copied_df.append(row2add,ignore_index=True)\n",
        "                break\n",
        "            else:\n",
        "              date = pseudoreturn_dates[season_second]\n",
        "              row2add = {'Date':date,'Team':Team,'Acquired':player_name,'Relinquished':acquired_name,'Notes':acquired_note,'Affected Player':player_name,'Season':season_second,'Injury Type':'','Injury Part':'Acquired'}\n",
        "              copied_df=copied_df.append(row2add,ignore_index=True)\n",
        "              break\n",
        "print(to_drop)\n",
        "copied_df = copied_df.reset_index(drop=True)\n",
        "copied_df = copied_df.drop(labels=to_drop,axis=0)\n",
        "copied_df = copied_df.reset_index(drop=True)\n",
        "copied_df['Date']=pd.to_datetime(copied_df['Date'])\n",
        "copied_df = copied_df.sort_values(by='Date')\n",
        "copied_df = copied_df.reset_index(drop=True)\n",
        "df = copied_df.copy()\n",
        "backup = copied_df.copy()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'1992-93': '1992-10-01', '1993-94': '1993-10-01', '1994-95': '1994-10-01', '1995-96': '1995-10-01', '1996-97': '1996-10-01', '1997-98': '1997-10-01', '1998-99': '1998-10-01', '1999-00': '1999-10-01', '2000-01': '2000-10-01', '2001-02': '2001-10-01', '2002-03': '2002-10-01', '2003-04': '2003-10-01', '2004-05': '2004-10-01', '2005-06': '2005-10-01', '2006-07': '2006-10-01', '2007-08': '2007-10-01', '2008-09': '2008-10-01', '2009-10': '2009-10-01', '2010-11': '2010-10-01', '2011-12': '2011-10-01', '2012-13': '2012-10-01', '2013-14': '2013-10-01'}\n",
            "{'1992-93': '1992-11-09', '1993-94': '1993-11-08', '1994-95': '1994-11-07', '1995-96': '1995-11-06', '1996-97': '1996-11-04', '1997-98': '1997-11-03', '1998-99': '1999-02-07', '1999-00': '1999-11-05', '2000-01': '2000-11-03', '2001-02': '2001-11-02', '2002-03': '2002-11-02', '2003-04': '2003-11-01', '2004-05': '2004-11-05', '2005-06': '2005-11-04', '2006-07': '2006-11-03', '2007-08': '2007-11-03', '2008-09': '2008-11-01', '2009-10': '2009-11-01', '2010-11': '2010-11-01', '2011-12': '2011-12-28', '2012-13': '2012-11-03', '2013-14': '2013-10-01'}\n",
            "[12281, 12240, 12254, 12302, 12319, 12289, 12245, 13636, 13656, 13675, 13708, 13687, 13723, 13672, 13639, 15368, 15353, 15388, 16336, 16375, 16360, 16344, 16341, 16365, 16335, 16331]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlREcZwf8iO1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cffe9af-d6da-4a0b-e8e1-f538ebb48d0b"
      },
      "source": [
        "df = copied_df.copy()\n",
        "rng = copied_df.shape[0]\n",
        "double_relinquished = []\n",
        "#double checking to see if there are any instances of a player\n",
        "#being relinquished two times in a row without being acquired\n",
        "for i in range(rng):\n",
        "  row = copied_df.iloc[i,:]\n",
        "  player_name = row.loc['Affected Player']\n",
        "  relinquished_name = row.loc['Relinquished']\n",
        "  acquired_name = row.loc['Acquired']\n",
        "  if player_name == relinquished_name:\n",
        "    for z in range(i+1,rng):\n",
        "      next_row = copied_df.iloc[z,:]\n",
        "      next_player_name = next_row.loc['Affected Player']\n",
        "      next_relinquished_name = next_row.loc['Relinquished']\n",
        "      next_acquired_name = next_row.loc['Acquired']\n",
        "      if next_acquired_name==player_name:\n",
        "        break\n",
        "      elif next_relinquished_name==player_name:\n",
        "        double_relinquished.append([i,z])\n",
        "        break\n",
        "      else:\n",
        "        continue\n",
        "\n",
        "\n",
        "drop_ici = []\n",
        "copied_df = df.copy()\n",
        "for i in range(len(double_relinquished)):\n",
        "  drop_ici.append(double_relinquished[i][0])\n",
        "copied_df = copied_df.reset_index(drop=True)\n",
        "copied_df = copied_df.drop(labels=drop_ici,axis=0)\n",
        "copied_df = copied_df.reset_index(drop=True)\n",
        "copied_df['Date']=pd.to_datetime(copied_df['Date'])\n",
        "# backup = copied_df.copy()\n",
        "copied_df = backup.copy()\n",
        "df = backup.copy()\n",
        "\n",
        "#after adding in the generic rows\n",
        "#we are ready to create a function and a column\n",
        "#to determine the exact duration of a particular injury\n",
        "\n",
        "def determine_injury_length(row):\n",
        "  rng = copied_df.shape[0]\n",
        "  notes = row.loc['Notes']\n",
        "  player_name = row.loc['Affected Player']\n",
        "  relinquished_name = row.loc['Relinquished']\n",
        "  acquired_name = row.loc['Acquired']\n",
        "  season_first = row.loc['Season']\n",
        "  date = row.loc['Date']\n",
        "  row_loc = copied_df.index[((copied_df['Date']==date) & (copied_df['Affected Player'] == player_name))][0]\n",
        "  if player_name == relinquished_name:\n",
        "    for z in range(row_loc+1,rng):\n",
        "      next_row = copied_df.iloc[z,:]\n",
        "      next_player_name = next_row.loc['Affected Player']\n",
        "      next_relinquished_name = next_row.loc['Relinquished']\n",
        "      next_acquired_name = next_row.loc['Acquired']\n",
        "      next_date = next_row.loc['Date']\n",
        "      if (player_name == next_player_name):\n",
        "        if (player_name == next_acquired_name):\n",
        "          return (next_date - date).days\n",
        "        else:\n",
        "           return 'ERROR'\n",
        "      elif (z == (rng-1)):\n",
        "        return 'Never Acquired Again'\n",
        "      else:\n",
        "        continue\n",
        "  else:\n",
        "    return 'Acquired'\n",
        "copied_df['Injury Duration']=df.apply(lambda row:determine_injury_length(row), axis=1)\n",
        "\n",
        "copied_df.to_csv('cleaned_names_1.csv')\n",
        "!gupload --to '12W7wtP_PL3oV5osKCwxM2cQWxzu1yETv' cleaned_names_1.csv\n",
        "print('Finished')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploading file: cleaned_names_1.csv\n",
            "Finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QprtbXDs8oRA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba4afde6-6343-43fe-e151-1842a4e8b815"
      },
      "source": [
        "#deleting others and miscellaneous here\n",
        "#as well as the 'never acquired again' instances\n",
        "#i.e. the instances that won't be very useful to our data\n",
        "\n",
        "copied_df = copied_df.reset_index(drop=True)\n",
        "df = copied_df.copy()\n",
        "rng = copied_df.shape[0]\n",
        "to_drop = []\n",
        "for i in range(rng):\n",
        "  row = copied_df.iloc[i,:]\n",
        "  player_name = row.loc['Affected Player']\n",
        "  relinquished_name = row.loc['Relinquished']\n",
        "  acquired_name = row.loc['Acquired']\n",
        "  injury_part = row.loc['Injury Part']\n",
        "  injury_duration = row.loc['Injury Duration']\n",
        "  mask1= (injury_part == 'other')\n",
        "  mask2 = (injury_part == 'miscellaneous')\n",
        "  mask3 = (injury_duration == 'Never Acquired Again')\n",
        "  mask4 = (injury_duration == 'Acquired')\n",
        "  mask5 = (injury_part == 'mental illness')\n",
        "  mask6 = (injury_part == 'illness')\n",
        "  mask8 = (injury_duration == 'ERROR')\n",
        "  masklst = [mask1,mask2,mask3,mask4,mask5,mask6,mask8]\n",
        "  if any(masklst):\n",
        "    to_drop.append(i)\n",
        "  else:\n",
        "    continue\n",
        "print(to_drop)\n",
        "copied_df = copied_df.reset_index(drop=True)\n",
        "copied_df = copied_df.drop(labels=to_drop,axis=0)\n",
        "copied_df = copied_df.reset_index(drop=True)\n",
        "\n",
        "df = copied_df.copy()\n",
        "rng = copied_df.shape[0]\n",
        "to_drop = []\n",
        "#also deleting instances where the injury is over 725 days\n",
        "#as that can skew our data \n",
        "for i in range(rng):\n",
        "  row = copied_df.iloc[i,:]\n",
        "  player_name = row.loc['Affected Player']\n",
        "  relinquished_name = row.loc['Relinquished']\n",
        "  acquired_name = row.loc['Acquired']\n",
        "  injury_part = row.loc['Injury Part']\n",
        "  injury_duration = row.loc['Injury Duration']\n",
        "  mask7 = (injury_duration > 725)\n",
        "  if mask7:\n",
        "    to_drop.append(i)\n",
        "copied_df = copied_df.reset_index(drop=True)\n",
        "copied_df = copied_df.drop(labels=to_drop,axis=0)\n",
        "copied_df = copied_df.reset_index(drop=True)\n",
        "df = copied_df.copy()\n",
        "backup2=df.copy()\n",
        "copied_df.to_csv('cleaned_names_1.csv')\n",
        "!gupload --to '12W7wtP_PL3oV5osKCwxM2cQWxzu1yETv' cleaned_names_1.csv\n",
        "print('Finished')\n",
        "\n",
        "print('Done latest iteration')\n",
        "\n",
        "#making a new DF where it has a list of players and the duration they've been out for various injuries\n",
        "#as well as showing exactly how many injuries they incurred to each body part\n",
        "rng = copied_df.shape[0]\n",
        "player_history_dict = {}\n",
        "for i in range(rng):\n",
        "  row = copied_df.iloc[i,:]\n",
        "  player_name = row.loc['Affected Player']\n",
        "  injury_part = row.loc['Injury Part']\n",
        "  injury_duration = row.loc['Injury Duration']\n",
        "  if player_name in player_history_dict:\n",
        "    player_history_dict[player_name][injury_part] += injury_duration\n",
        "    player_history_dict[player_name][injury_part+'_count'] += 1\n",
        "  else:\n",
        "    row2add = {'foot':0,'knee':0,'upper leg':0,'lower leg':0,'back':0,'arm':0,'hand':0,'upper body':0,'core and hip':0,'head and neck':0,'foot_count':0,'knee_count':0,'upper leg_count':0,'lower leg_count':0,'back_count':0,'arm_count':0,'hand_count':0,'upper body_count':0,'core and hip_count':0,'head and neck_count':0}\n",
        "    row2add[injury_part] += injury_duration\n",
        "    row2add[injury_part+'_count'] += 1\n",
        "    player_history_dict[player_name]=row2add\n",
        "\n",
        "#the player injury history is the data we will use to help our analysis\n",
        "#with injuries post 2013 \n",
        "#a player's injury history may have a great impact on the severity of their future injuries\n",
        "player_history = pd.DataFrame.from_dict(player_history_dict, orient='index')\n",
        "player_history.to_csv('FINAL_player_injury_history.csv')\n",
        "!gupload --to '12W7wtP_PL3oV5osKCwxM2cQWxzu1yETv' FINAL_player_injury_history.csv\n",
        "print('Finished')\n",
        "print('Done latest iteration')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "Uploading file: cleaned_names_1.csv\n",
            "Finished\n",
            "Done latest iteration\n",
            "Uploading file: FINAL_player_injury_history.csv\n",
            "Finished\n",
            "Done latest iteration\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UYU9baRJZvd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
